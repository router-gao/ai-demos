# Colab Intro

https://colab.research.google.com/

https://research.google.com/colaboratory/faq.html

Key features of Colab include:

- Browser-based Python environment so no local setup needed
- Free/Paid access to GPUs for accelerated computing
- Easy sharing and collaboration on notebooks
- Integration with Google Drive for storage
- Support for popular libraries like TensorFlow, PyTorch, Keras
- Fast iteration with no environment management overhead
- Available mobile app for on-the-go use
- Usage limits based on available compute resources

Most features will be covered in the Demo below.

# General Process

- Download Llama-2-7B model from Github
- Convert the model 'Llama-2-7B' into Hugging Face (HF) format 'Llama-2-7B-HF'
- Download fine-tune Demo project from Github (llama-recipes, which is also open sourced by Meta. It's designed to demo the process of Llama-2-7B fine-tuning https://github.com/facebookresearch/llama-recipes)
- Test Lllama-2-7B model before fine-tuning - result is not very good.
- Fine-tune the Llama-2-7B-HF model (90 mins with A100 GPU)
- Test the tuned model with project 'llama-recipes'
- Save the model to Google drive
- Save/Download/Share the Jupyter notebook file (*.ipynb)

# Introduction of Fine-tuning Demo project llama-recipes

https://github.com/facebookresearch/llama-recipes

https://github.com/facebookresearch/llama-recipes/tree/main/examples

Project llama-recipes uses Dataset samsum to fine-tune the model.

# Introduction of Dataset samsum



- The SAMSum dataset contains about 16k messenger-like conversations with summaries.
- Conversations were created and written down by linguists fluent in English.
- Linguists were asked to create conversations similar to those they write on a daily basis, reflecting the proportion of topics of their real-life messenger conversations. 



https://huggingface.co/datasets

Search the Datasets as below